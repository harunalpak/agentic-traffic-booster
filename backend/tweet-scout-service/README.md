# Tweet Scout Service

**Autonomous Tweet Discovery Microservice for Agentic Traffic Booster**

## ğŸ¯ Purpose

The Tweet Scout Service is a dedicated Node.js microservice that autonomously discovers relevant tweets for active marketing campaigns. It uses the Twitter Scraper to find public tweets matching campaign criteria and publishes them to Kafka for downstream processing.

## ğŸ—ï¸ Architecture

### Refactored from Java to Node.js

**Before:** TweetScout was a scheduled component within `social-engine-service` (Java)

**After:** Independent microservice with dedicated responsibility

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tweet Scout Service       â”‚
â”‚      (Node.js)              â”‚
â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Cron Scheduler     â”‚    â”‚
â”‚  â”‚ (every 30 min)     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚            â”‚                â”‚
â”‚            â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Campaign Client    â”‚â”€â”€â”€â”€â”¼â”€â”€â†’ campaign-service
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚        (HTTP)
â”‚            â”‚                â”‚
â”‚            â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Twitter Scraper    â”‚    â”‚
â”‚  â”‚ (@the-convocation) â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚            â”‚                â”‚
â”‚            â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Kafka Producer     â”‚â”€â”€â”€â”€â”¼â”€â”€â†’ new_tweets topic
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚        (Kafka)
â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§© Core Components

### 1. Scheduler (`scoutScheduler.js`)
- Cron-based execution (configurable interval)
- Fetches active campaigns
- Orchestrates scraping and publishing
- Comprehensive logging and error handling

### 2. Campaign Client (`campaignClient.js`)
- HTTP client to fetch active campaigns
- Communicates with `campaign-service`
- Error handling and retry logic

### 3. Tweet Scraper (`tweetScraper.js`)
- Uses `@the-convocation/twitter-scraper`
- Builds search queries from hashtags/keywords
- Mock tweet generation for development
- Rate limiting and error handling

### 4. Tweet Publisher (`tweetPublisher.js`)
- Kafka producer using `kafkajs`
- Batch message publishing
- Dead letter queue for failures
- Message key based on tweet ID

### 5. Kafka Configuration (`kafka.js`)
- Kafka client setup
- Topic definitions
- Producer connection management
- Graceful shutdown

## ğŸ“Š Data Flow

```
1. Cron Trigger (every 30 min)
   â†“
2. Fetch Active Campaigns
   â† campaign-service (HTTP GET)
   â†“
3. For Each Campaign:
   â”œâ”€ Build search query
   â”œâ”€ Scrape tweets
   â””â”€ Publish to Kafka
      â†“
4. Kafka Topic: new_tweets
   â†“
5. Consumed by: social-engine-service
```

## ğŸ“¡ Kafka Topics

### Published Topics

#### `new_tweets`
Messages published to this topic:

```json
{
  "tweetId": "1878383920",
  "campaignId": 12,
  "author": "JaneDoe",
  "text": "Any handmade Christmas ideas?",
  "url": "https://twitter.com/JaneDoe/status/1878383920",
  "likes": 42,
  "retweets": 7,
  "replies": 3,
  "language": "en",
  "createdAt": "2025-11-14T12:00:00.000Z"
}
```

#### `dead_letter`
Failed messages sent to DLQ:

```json
{
  "campaignId": 12,
  "tweets": [...],
  "error": "Error message",
  "timestamp": "2025-11-14T12:00:00.000Z",
  "service": "tweet-scout-service"
}
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 20+
- Kafka 3.x
- Campaign Service running on port 8082

### Installation

```bash
# Install dependencies
npm install

# Copy environment template
cp env.template .env

# Edit .env with your configuration
nano .env
```

### Configuration

Required environment variables:

```bash
KAFKA_BROKERS=localhost:9092
CAMPAIGN_SERVICE_URL=http://localhost:8082
SCRAPE_INTERVAL_MINUTES=30
MAX_TWEETS_PER_CAMPAIGN=10
```

### Run Locally

```bash
# Development mode (with auto-reload)
npm run dev

# Production mode
npm start
```

### Run with Docker

```bash
# Build and start all services
docker-compose up -d

# View logs
docker-compose logs -f tweet-scout-service

# Stop services
docker-compose down
```

## ğŸ“‹ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `KAFKA_BROKERS` | Kafka broker addresses | `localhost:9092` |
| `CAMPAIGN_SERVICE_URL` | Campaign service URL | `http://localhost:8082` |
| `SCRAPE_INTERVAL_MINUTES` | Scout execution interval | `30` |
| `MAX_TWEETS_PER_CAMPAIGN` | Max tweets per campaign | `10` |
| `USE_MOCK_TWEETS` | Use mock data if scraping fails | `false` |
| `RUN_ON_STARTUP` | Run scout on service startup | `true` |
| `LOG_LEVEL` | Logging level | `info` |
| `NODE_ENV` | Environment | `development` |
| `TZ` | Timezone for scheduler | `UTC` |

## ğŸ“ Example Logs

```
[INFO] ========================================
[INFO] ğŸ” Tweet Scout: Starting tweet discovery
[INFO] ========================================
[INFO] ğŸ“¡ Fetching active campaigns from: http://localhost:8082
[INFO] âœ… Retrieved 3 active campaigns
[INFO] ğŸ“‹ Processing 3 active campaigns
[INFO] ----------------------------------------
[INFO] ğŸ“Œ Campaign: Handmade Xmas (ID: 1)
[INFO]    Mode: SEMI_AUTO
[INFO]    Status: ACTIVE
[INFO]    Query: "#handmade OR #Christmas OR #gifts"
[INFO] ğŸ” Scraping tweets for query: "#handmade OR #Christmas OR #gifts" (limit: 10)
[INFO] âœ… Found 7 tweets
[INFO] ğŸ“¨ Found 7 tweets
[INFO] âœ… Published 7 tweets to Kafka
[INFO] ========================================
[INFO] ğŸ“Š Tweet Scout Summary:
[INFO]    Campaigns Processed: 3
[INFO]    Campaigns Failed: 0
[INFO]    Total Tweets Found: 18
[INFO]    Total Tweets Published: 18
[INFO]    Duration: 12.45s
[INFO] ========================================
[INFO] â° Next execution in 30 minutes
[INFO] ========================================
```

## ğŸ§ª Testing

### Mock Tweet Mode

For development without Twitter access:

```bash
# In .env
USE_MOCK_TWEETS=true
RUN_ON_STARTUP=true
SCRAPE_INTERVAL_MINUTES=5
```

This will generate mock tweets for testing the pipeline.

### Kafka Testing

Monitor messages in Kafka:

```bash
# Watch new_tweets topic
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic new_tweets \
  --from-beginning \
  --property print.key=true
```

## ğŸ“Š Performance

### Throughput
- **Campaigns per minute:** ~10-20 (depends on tweet scraping)
- **Tweets per campaign:** Configurable (default: 10)
- **Total tweets per run:** ~50-200

### Resource Usage
- **Memory:** ~100-200MB
- **CPU:** Low (mostly I/O bound)
- **Network:** Moderate (HTTP + Kafka)

### Scalability
- Single instance sufficient for most use cases
- Can scale horizontally for higher load
- Kafka producer handles batching efficiently

## ğŸ” Security Considerations

### Current Implementation
- âœ… Non-root Docker user
- âœ… Environment-based configuration
- âœ… Error handling with DLQ

### Production Recommendations
- [ ] Use Twitter API credentials securely
- [ ] Implement rate limiting
- [ ] Add authentication for inter-service communication
- [ ] Use secrets manager for sensitive data
- [ ] Enable Kafka SSL/SASL
- [ ] Implement monitoring and alerting

## ğŸ› ï¸ Troubleshooting

### Service won't start

```bash
# Check if Kafka is running
docker ps | grep kafka

# Check logs
docker-compose logs tweet-scout-service
```

### No tweets found

```bash
# Enable mock tweets for testing
USE_MOCK_TWEETS=true

# Check campaign service
curl http://localhost:8082/api/campaigns
```

### Kafka connection failed

```bash
# Check Kafka brokers
kafka-broker-api-versions.sh --bootstrap-server localhost:9092

# Verify topic exists
kafka-topics.sh --bootstrap-server localhost:9092 --list
```

### Campaign service unreachable

```bash
# Test connection
curl http://localhost:8082/api/campaigns

# Check Docker network
docker network inspect tweet-scout-network
```

## ğŸ”„ Migration from Java

### What was removed from social-engine-service

âŒ `TweetScoutScheduler.java` - Deleted  
âŒ `searchTwitter()` method - Removed  
âŒ `searchTwitterViaNodeScript()` - Removed  
âŒ `@Scheduled` annotation - No longer needed  

### What remains in social-engine-service

âœ… Kafka consumer for `new_tweets` topic  
âœ… ReplyGenerator module  
âœ… TaskManager module  
âœ… All other services  

## ğŸ“š Related Services

- **campaign-service** (Port 8082) - Campaign management
- **social-engine-service** (Port 8083) - Reply generation & task management
- **product-service** (Port 8080) - Product catalog

## ğŸš€ Future Enhancements

1. **Twitter API v2 Integration** - Official API support
2. **Real-time Streaming** - Twitter streaming API
3. **Advanced Filtering** - Sentiment analysis, language detection
4. **Rate Limiting** - Respect Twitter rate limits
5. **Caching** - Redis for tweet deduplication
6. **Metrics** - Prometheus metrics export
7. **Dashboard** - Real-time monitoring UI
8. **Multi-platform** - Support for other social networks

## ğŸ“„ License

Part of the Agentic Traffic Booster project.

## ğŸ‘¥ Contact

For questions or issues, refer to the main ATB project documentation.

---

**Built with:** Node.js 20, @the-convocation/twitter-scraper, kafkajs, node-cron

**Version:** 1.0.0

**Last Updated:** November 2024
